{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyMKQolOUQ6tqZE0VIq8Hqtu"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ym5GZ2GEpv9b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152003478,
     "user_tz": -180,
     "elapsed": 2473,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "outputId": "695bbd54-dec8-4330-8736-9100b07a3138",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd 'project/path/'\n",
    "%ls\n",
    "import os\n",
    "path = os.getcwd()\n",
    "print('path: ' + path)\n",
    "OutputPath = path + '/Output'\n",
    "ModelPath = path + '/Models'"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcUgdV7Wp3qr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152003478,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "outputId": "f495e81e-f19c-4a8a-cfc9-95d30e2faa0b",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ],
   "metadata": {
    "id": "Fc83WmYHs_ax",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152003478,
     "user_tz": -180,
     "elapsed": 3,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset function in DataLoader.py at work folder\n",
    "from DataLoader import FashionMNISTDataset"
   ],
   "metadata": {
    "id": "mrPsQ0iBuX3D",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152003478,
     "user_tz": -180,
     "elapsed": 3,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# This row is for defining if running training section in this document\n",
    "trainMode = False"
   ],
   "metadata": {
    "id": "9k6l8P-fNW9u",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152003478,
     "user_tz": -180,
     "elapsed": 3,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Data transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "data_path = path + '/FashionMNIST'\n",
    "\n",
    "# Paths\n",
    "train_images_path = os.path.join(data_path, 'train-images-idx3-ubyte.gz')\n",
    "train_labels_path = os.path.join(data_path, 'train-labels-idx1-ubyte.gz')\n",
    "test_images_path = os.path.join(data_path, 't10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = os.path.join(data_path, 't10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "# Dataset objects\n",
    "full_train_dataset = FashionMNISTDataset(train_images_path, train_labels_path, transform=transform)\n",
    "test_dataset = FashionMNISTDataset(test_images_path, test_labels_path, transform=transform)\n",
    "\n",
    "# Trian n validation split\n",
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader objects\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "print(f'Batch of images has shape: {images.shape}')\n",
    "print(f'Batch of labels has shape: {labels.shape}')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjwJ1NKrwd_Y",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152004413,
     "user_tz": -180,
     "elapsed": 938,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "outputId": "f50cda5d-6410-4df6-b33b-579a30f9a5a4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch of images has shape: torch.Size([64, 1, 28, 28])\n",
      "Batch of labels has shape: torch.Size([64])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Base Model LeNet5\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "metadata": {
    "id": "PLXLYHDeuaMK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152005044,
     "user_tz": -180,
     "elapsed": 633,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#LeNet5 with dropout\n",
    "class LeNet5Dropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5Dropout, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "metadata": {
    "id": "ucxnDW1Oujpz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152005044,
     "user_tz": -180,
     "elapsed": 8,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#LeNet5 with Batch Normalization\n",
    "class LeNet5BatchNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5BatchNorm, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.BatchNorm1d(120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.BatchNorm1d(84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "metadata": {
    "id": "TtuH3_Qj2AM9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152005044,
     "user_tz": -180,
     "elapsed": 8,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Model test function\n",
    "def test_model(model, data_loader, eval_dropout=False):\n",
    "    if eval_dropout:\n",
    "        model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    if eval_dropout:\n",
    "        model.train()\n",
    "    return accuracy\n"
   ],
   "metadata": {
    "id": "_A5QDqCp8eD9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152005044,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Model train function + saving accuracies\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, n_epochs=10, eval_dropout=False):\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy for train and test data\n",
    "        train_acc = test_model(model, train_loader, eval_dropout)\n",
    "        test_acc = test_model(model, test_loader)\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "\n",
    "        print(f'[Epoch {epoch + 1}] Train Acc: {train_acc:.2f}%, Validation Acc: {test_acc:.2f}%')\n",
    "\n",
    "    print('Finished Training')\n",
    "    return train_accuracies, test_accuracies\n"
   ],
   "metadata": {
    "id": "ErtZ9SIY8M2R",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152005044,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def save_model(model, name):\n",
    "    path = os.path.join(ModelPath, name)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f'Model saved to {path}')\n",
    "\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    print(f'Model loaded from {path}')"
   ],
   "metadata": {
    "id": "6HpsyqXr7DEt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152005044,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if trainMode:\n",
    "    # Define the models to train\n",
    "    model_base = LeNet5()\n",
    "    model_dropout = LeNet5Dropout()\n",
    "    model_batchnorm = LeNet5BatchNorm()\n",
    "    model_base_wd = LeNet5()\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training parameters\n",
    "    learning_rate = 0.0002\n",
    "    n_epochs = 50\n",
    "    weight_decay = 0.0005\n",
    "\n",
    "    # Optimizers\n",
    "    optimizer_base = optim.Adam(model_base.parameters(), lr=learning_rate)\n",
    "    optimizer_dropout = optim.Adam(model_dropout.parameters(), lr=learning_rate)\n",
    "    optimizer_batchnorm = optim.Adam(model_batchnorm.parameters(), lr=learning_rate)\n",
    "    optimizer_base_wd = optim.Adam(model_base_wd.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ],
   "metadata": {
    "id": "6Ty17YAl59jV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152005044,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if trainMode:\n",
    "    # Train and save the base model\n",
    "    print(\"Training the base LeNet-5 model:\")\n",
    "    train_accuracies_base, val_accuracies_base = train_model(model_base, train_loader, val_loader, criterion, optimizer_base, n_epochs=n_epochs)\n",
    "    save_model(model_base, 'lenet5_base.pth')\n",
    "\n",
    "    # Train and save the model with dropout\n",
    "    print(\"Training the LeNet-5 model with Dropout:\")\n",
    "    train_accuracies_dropout, val_accuracies_dropout = train_model(model_dropout, train_loader, val_loader, criterion, optimizer_dropout, n_epochs=n_epochs, eval_dropout=True)\n",
    "    save_model(model_dropout, 'lenet5_dropout.pth')\n",
    "\n",
    "    # Train and save the model with batch normalization\n",
    "    print(\"Training the LeNet-5 model with Batch Normalization:\")\n",
    "    train_accuracies_batchnorm, val_accuracies_batchnorm = train_model(model_batchnorm, train_loader, val_loader, criterion, optimizer_batchnorm, n_epochs=n_epochs)\n",
    "    save_model(model_batchnorm, 'lenet5_batchnorm.pth')\n",
    "\n",
    "    # Train and save the base model with weight decay\n",
    "    print(\"Training the base LeNet-5 model with Weight Decay:\")\n",
    "    train_accuracies_base_wd, val_accuracies_base_wd = train_model(model_base_wd, train_loader, val_loader, criterion, optimizer_base_wd, n_epochs=n_epochs)\n",
    "    save_model(model_base_wd, 'lenet5_base_wd.pth')\n",
    "\n",
    "    # Save all train and test accuracies per epoch\n",
    "    data = {\n",
    "        'Epoch': list(range(1, n_epochs + 1)),\n",
    "        'Train_Accuracy_Base': train_accuracies_base,\n",
    "        'Validaiton_Accuracy_Base': val_accuracies_base,\n",
    "        'Train_Accuracy_Dropout': train_accuracies_dropout,\n",
    "        'Validaiton_Accuracy_Dropout': val_accuracies_dropout,\n",
    "        'Train_Accuracy_BatchNorm': train_accuracies_batchnorm,\n",
    "        'Validaiton_Accuracy_BatchNorm': val_accuracies_batchnorm,\n",
    "        'Train_Accuracy_Base_WD': train_accuracies_base_wd,\n",
    "        'Validaiton_Accuracy_Base_WD': val_accuracies_base_wd,\n",
    "    }\n",
    "\n",
    "    df_accuracies = pd.DataFrame(data)\n",
    "    df_accuracies.to_csv(os.path.join(OutputPath,'model_accuracies_per_epoch.csv'), index=False)\n",
    "    print(\"Model accuracies per epoch saved to 'model_accuracies_per_epoch.csv'\")\n"
   ],
   "metadata": {
    "id": "3vhsspVR7TL-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152005044,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_convergence_graphs(train_accuracies_base, val_accuracies_base,\n",
    "                            train_accuracies_dropout, val_accuracies_dropout,\n",
    "                            train_accuracies_batchnorm, val_accuracies_batchnorm,\n",
    "                            train_accuracies_base_wd, val_accuracies_base_wd):\n",
    "    epochs = range(1, len(train_accuracies_base) + 1)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "    # Plot Base LeNet-5\n",
    "    axs[0, 0].plot(epochs, train_accuracies_base, label='Train Accuracy')\n",
    "    axs[0, 0].plot(epochs, val_accuracies_base, label='Validation Accuracy')\n",
    "    axs[0, 0].set_title('LeNet-5')\n",
    "    axs[0, 0].set_xlabel('Epochs')\n",
    "    axs[0, 0].set_ylabel('Accuracy (%)')\n",
    "    axs[0,0].grid(True)\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    # Plot LeNet-5 with Dropout\n",
    "    axs[0, 1].plot(epochs, train_accuracies_dropout, label='Train Accuracy')\n",
    "    axs[0, 1].plot(epochs, val_accuracies_dropout, label='Validation Accuracy')\n",
    "    axs[0, 1].set_title('LeNet-5 with Dropout')\n",
    "    axs[0, 1].set_xlabel('Epochs')\n",
    "    axs[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axs[0, 1].grid(True)\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    # Plot LeNet-5 with Batch Normalization\n",
    "    axs[1, 0].plot(epochs, train_accuracies_batchnorm, label='Train Accuracy')\n",
    "    axs[1, 0].plot(epochs, val_accuracies_batchnorm, label='Validation Accuracy')\n",
    "    axs[1, 0].set_title('LeNet-5 with Batch Normalization')\n",
    "    axs[1, 0].set_xlabel('Epochs')\n",
    "    axs[1, 0].set_ylabel('Accuracy (%)')\n",
    "    axs[1, 0].grid(True)\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    # Plot Base LeNet-5 with Weight Decay\n",
    "    axs[1, 1].plot(epochs, train_accuracies_base_wd, label='Train Accuracy')\n",
    "    axs[1, 1].plot(epochs, val_accuracies_base_wd, label='Validation Accuracy')\n",
    "    axs[1, 1].set_title('LeNet-5 with Weight Decay')\n",
    "    axs[1, 1].set_xlabel('Epochs')\n",
    "    axs[1, 1].set_ylabel('Accuracy (%)')\n",
    "    axs[1, 1].grid(True)\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('convergence_graphs.png')\n",
    "    plt.show()\n",
    "\n",
    "    return fig"
   ],
   "metadata": {
    "id": "_ntY0dvTAS0V",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152005044,
     "user_tz": -180,
     "elapsed": 6,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_models():\n",
    "    # Define the models again\n",
    "    model_base = LeNet5()\n",
    "    model_dropout = LeNet5Dropout()\n",
    "    model_batchnorm = LeNet5BatchNorm()\n",
    "    model_base_wd = LeNet5()\n",
    "\n",
    "    # Load model comstants\n",
    "    load_model(model_base, os.path.join(ModelPath,'lenet5_base.pth'))\n",
    "    load_model(model_dropout, os.path.join(ModelPath,'lenet5_dropout.pth'))\n",
    "    load_model(model_batchnorm, os.path.join(ModelPath,'lenet5_batchnorm.pth'))\n",
    "    load_model(model_base_wd, os.path.join(ModelPath,'lenet5_base_wd.pth'))\n",
    "\n",
    "    return model_base, model_dropout, model_batchnorm, model_base_wd"
   ],
   "metadata": {
    "id": "GhBg0LjuCX0V",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152005045,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_and_evaluate_models():\n",
    "    # Define the models again\n",
    "    model_base, model_dropout, model_batchnorm, model_base_wd = load_models()\n",
    "\n",
    "    # Test models\n",
    "    test_accuracy_base = test_model(model_base, test_loader)\n",
    "    test_accuracy_dropout = test_model(model_dropout, test_loader)\n",
    "    test_accuracy_batchnorm = test_model(model_batchnorm, test_loader)\n",
    "    test_accuracy_base_wd = test_model(model_base_wd, test_loader)\n",
    "\n",
    "    # Train history data from CSV\n",
    "    accuracies_df = pd.read_csv(os.path.join(OutputPath,'model_accuracies_per_epoch.csv'))\n",
    "    train_accuracies_base = accuracies_df['Train_Accuracy_Base']\n",
    "    train_accuracies_dropout = accuracies_df['Train_Accuracy_Dropout']\n",
    "    train_accuracies_batchnorm = accuracies_df['Train_Accuracy_BatchNorm']\n",
    "    train_accuracies_base_wd = accuracies_df['Train_Accuracy_Base_WD']\n",
    "    val_accuracies_base = accuracies_df['Validaiton_Accuracy_Base']\n",
    "    val_accuracies_dropout = accuracies_df['Validaiton_Accuracy_Dropout']\n",
    "    val_accuracies_batchnorm = accuracies_df['Validaiton_Accuracy_BatchNorm']\n",
    "    val_accuracies_base_wd = accuracies_df['Validaiton_Accuracy_Base_WD']\n",
    "\n",
    "    # Print summary table\n",
    "    data = {\n",
    "        \"Model\": [\n",
    "            \"Base LeNet-5\",\n",
    "            \"LeNet-5 with Dropout\",\n",
    "            \"LeNet-5 with Batch Normalization\",\n",
    "            \"Base LeNet-5 with Weight Decay\"\n",
    "        ],\n",
    "        \"Final Train Accuracy (%)\": [\n",
    "            train_accuracies_base.iloc[-1],\n",
    "            train_accuracies_dropout.iloc[-1],\n",
    "            train_accuracies_batchnorm.iloc[-1],\n",
    "            train_accuracies_base_wd.iloc[-1]\n",
    "        ],\n",
    "        \"Final Validation Accuracy (%)\": [\n",
    "            val_accuracies_base.iloc[-1],\n",
    "            val_accuracies_dropout.iloc[-1],\n",
    "            val_accuracies_batchnorm.iloc[-1],\n",
    "            val_accuracies_base_wd.iloc[-1]\n",
    "        ],\n",
    "        \"Final Test Accuracy (%)\": [\n",
    "            test_accuracy_base,\n",
    "            test_accuracy_dropout,\n",
    "            test_accuracy_batchnorm,\n",
    "            test_accuracy_base_wd\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df)\n",
    "\n",
    "    # Save summary table as image\n",
    "    df.to_csv(os.path.join(OutputPath,'summary_table.csv'))\n",
    "    print(\"Summary table saved to 'summary_table.csv'\")\n",
    "\n",
    "    # Plot convergence graphs\n",
    "    fig = plot_convergence_graphs(train_accuracies_base, val_accuracies_base,\n",
    "                            train_accuracies_dropout, val_accuracies_dropout,\n",
    "                            train_accuracies_batchnorm, val_accuracies_batchnorm,\n",
    "                            train_accuracies_base_wd, val_accuracies_base_wd)\n",
    "    return fig"
   ],
   "metadata": {
    "id": "9Tw0jMSdJyGU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152005045,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading and plotting\n",
    "fig = load_and_evaluate_models()\n",
    "fig.savefig('convergence_graphs.png')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 871
    },
    "id": "kAE8KXwK_U2r",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152018358,
     "user_tz": -180,
     "elapsed": 13320,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "outputId": "b23f3f60-f31a-4e9a-ba85-eeea0b8bc2fa",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Un-comment following code lines in order to run different test set from *.gz files\n",
    "\n",
    "#new_test_dataset = FashionMNISTDataset(test_images_path, test_labels_path, transform=transform)\n",
    "#test_loader = DataLoader(new_test_dataset, batch_size=64, shuffle=False)\n",
    "#test_accuracy = test_model(model, data_loader, eval_dropout=False)\n",
    "#print('Test Acc: {test_accuracy:.2f}')"
   ],
   "metadata": {
    "id": "TC86rzLsDr7T",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719152018358,
     "user_tz": -180,
     "elapsed": 5,
     "user": {
      "displayName": "Liran Moshe",
      "userId": "06520396858861458843"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 37,
   "outputs": []
  }
 ]
}